{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AyAOVcykluKl"
   },
   "source": [
    "# TFLite on Python\n",
    "## Import modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTlMWa7vh1ai"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/osamura/.local/share/virtualenvs/GoogleMVFaceDetectorResources-ualQ251a/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6cd130e2ca23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hqytek9Hk1Ca"
   },
   "source": [
    "## Loading the trained model\n",
    "Now a TFLite interpreter will be created, with the model being loaded upon the initialization of the interpreter. The input and output details of the model are then displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "56lgNv-Uh_2H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'pfld_inference/fc/BiasAdd',\n",
       "  'index': 156,\n",
       "  'shape': array([  1, 136], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(\"./pfld_growing68.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "output_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ct9q_ZE4mC9F"
   },
   "source": [
    "## Pre-processing of the input image\n",
    "Here the image is converted into array of a specified size (img_row x img_column) and a particular colour channel is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpKVVoBTj0ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = cv2.imread(\"image.png\")\n",
    "size = 112\n",
    "input_img = cv2.resize(input_img, (size, size))\n",
    "# red, green, blue = input_img.split()\n",
    "input_img = input_img.astype(np.float32)\n",
    "input_img = input_img / 256.0\n",
    "input_img.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0RuBMuY0ksOx",
    "outputId": "5ebd6816-c738-4c22-a866-760e65dc037d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 112, 112, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = input_img[np.newaxis, :, :, :]\n",
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = input_details[0]['shape']\n",
    "input_shape\n",
    "input_img = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IahCtqSXmUmi"
   },
   "source": [
    "## Running the Interpreter\n",
    "The input array is fed into the interpreter and the output is observed, as the output array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aW2Y9ngRkyt-",
    "outputId": "ad3469f1-7790-4ae0-dc4b-deeeecd55799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10706858 0.22383392 0.05651244 0.2645762  0.08970477 0.40228048\n",
      "  0.16634344 0.47091475 0.10559508 0.5668427  0.23927985 0.68145674\n",
      "  0.3596879  0.87124306 0.42985982 0.84644973 0.54748994 0.91592026\n",
      "  0.5872721  0.9178163  0.6196594  0.79017216 0.7539648  0.7231125\n",
      "  0.7962244  0.5647075  0.8658203  0.52514434 0.86346084 0.4313818\n",
      "  0.8799628  0.2726475  0.8583272  0.24043657 0.20470689 0.12687922\n",
      "  0.30868232 0.08336932 0.22690569 0.13204455 0.31051084 0.12995832\n",
      "  0.37999234 0.15356918 0.5589445  0.13612108 0.5593865  0.13479885\n",
      "  0.67558944 0.13465437 0.7075526  0.13683024 0.72738993 0.13328642\n",
      "  0.49430135 0.23622556 0.5108467  0.33103544 0.46028775 0.33490467\n",
      "  0.49001488 0.48096263 0.41502756 0.533693   0.41455832 0.5074614\n",
      "  0.4293368  0.506279   0.5332921  0.43557706 0.52308875 0.52472216\n",
      "  0.22118028 0.23776217 0.29928493 0.21785079 0.4408158  0.22678073\n",
      "  0.31800708 0.27588087 0.37372792 0.3114619  0.30827364 0.2138866\n",
      "  0.47995377 0.25104302 0.55411416 0.23368295 0.66220486 0.18427902\n",
      "  0.77180177 0.2966687  0.61282825 0.23984851 0.61115414 0.25932634\n",
      "  0.28336367 0.61921847 0.37089917 0.6056081  0.41480014 0.6199583\n",
      "  0.46334893 0.57649386 0.50671655 0.5607597  0.62281966 0.5821431\n",
      "  0.6206744  0.5369642  0.5887103  0.702194   0.53461164 0.6277717\n",
      "  0.5485815  0.6349494  0.41283333 0.7603805  0.36357698 0.6595189\n",
      "  0.32065335 0.5909084  0.3664393  0.56302804 0.46929395 0.5720313\n",
      "  0.5648379  0.5566564  0.58261526 0.61962676 0.5210192  0.62919074\n",
      "  0.43258584 0.6872396  0.44443616 0.6515471 ]]\n"
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], input_img)\n",
    "interpreter.invoke()\n",
    "pre_landmark = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(pre_landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11.9916805   25.06939888]\n",
      " [  6.32939303  29.63253403]\n",
      " [ 10.04693472  45.05541372]\n",
      " [ 18.63046479  52.74245214]\n",
      " [ 11.82664919  63.48637962]\n",
      " [ 26.79934335  76.3231554 ]\n",
      " [ 40.28504419  97.57922268]\n",
      " [ 48.14429951  94.80237007]\n",
      " [ 61.31887341 102.58306885]\n",
      " [ 65.77447605 102.79542351]\n",
      " [ 69.40185547  88.49928188]\n",
      " [ 84.44405556  80.98860264]\n",
      " [ 89.17713451  63.24724197]\n",
      " [ 96.97187233  58.81616592]\n",
      " [ 96.70761395  48.31476068]\n",
      " [ 98.55583382  30.53652   ]\n",
      " [ 96.13264751  26.92889571]\n",
      " [ 22.92717195  14.21047211]\n",
      " [ 34.57242012   9.33736408]\n",
      " [ 25.41343713  14.78899002]\n",
      " [ 34.77721453  14.55533147]\n",
      " [ 42.55914164  17.1997478 ]\n",
      " [ 62.60178661  15.24556088]\n",
      " [ 62.65128708  15.09747171]\n",
      " [ 75.66601753  15.08128977]\n",
      " [ 79.24589252  15.32498693]\n",
      " [ 81.46767235  14.92807865]\n",
      " [ 55.36175108  26.45726275]\n",
      " [ 57.21482754  37.07596874]\n",
      " [ 51.55222797  37.50932312]\n",
      " [ 54.88166666  53.86781502]\n",
      " [ 46.48308659  59.77361774]\n",
      " [ 46.43053198  56.83568001]\n",
      " [ 48.08572006  56.70324707]\n",
      " [ 59.72871685  48.78463125]\n",
      " [ 58.58594036  58.7688818 ]\n",
      " [ 24.77219081  26.62936282]\n",
      " [ 33.51991272  24.39928842]\n",
      " [ 49.37137032  25.39944148]\n",
      " [ 35.61679316  30.8986578 ]\n",
      " [ 41.85752678  34.88373232]\n",
      " [ 34.52664804  23.95529962]\n",
      " [ 53.75482178  28.11681843]\n",
      " [ 62.06078625  26.17248988]\n",
      " [ 74.1669445   20.63925076]\n",
      " [ 86.44179821  33.22689533]\n",
      " [ 68.63676453  26.86303306]\n",
      " [ 68.44926357  29.04454994]\n",
      " [ 31.73673105  69.35246849]\n",
      " [ 41.54070711  67.82810783]\n",
      " [ 46.45761538  69.43532753]\n",
      " [ 51.89507961  64.56731224]\n",
      " [ 56.75225353  62.805089  ]\n",
      " [ 69.75580215  65.20003033]\n",
      " [ 69.51552963  60.13998795]\n",
      " [ 65.9355545   78.64572525]\n",
      " [ 59.87650394  70.31042767]\n",
      " [ 61.44112587  71.11433125]\n",
      " [ 46.2373333   85.16261673]\n",
      " [ 40.72062159  73.86611652]\n",
      " [ 35.91317511  66.18174171]\n",
      " [ 41.04120302  63.05914021]\n",
      " [ 52.56092262  64.06750774]\n",
      " [ 63.26184177  62.34551907]\n",
      " [ 65.25290871  69.39819717]\n",
      " [ 58.35415268  70.46936321]\n",
      " [ 48.44961357  76.97083378]\n",
      " [ 49.77685022  72.97327232]]\n"
     ]
    }
   ],
   "source": [
    "pre_landmark = pre_landmark.reshape(-1, 2) * [size, size]\n",
    "print(pre_landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) /Users/travis/build/skvark/opencv-python/opencv/modules/core/src/array.cpp:2492: error: (-206:Bad flag (parameter or structure field)) Unrecognized or unsupported array type in function 'cvGetMat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-7b7c33872459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpre_landmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /Users/travis/build/skvark/opencv-python/opencv/modules/core/src/array.cpp:2492: error: (-206:Bad flag (parameter or structure field)) Unrecognized or unsupported array type in function 'cvGetMat'\n"
     ]
    }
   ],
   "source": [
    "for (x, y) in pre_landmark.astype(np.int32):\n",
    "    cv2.circle(input_img, (x, y), 5, (0, 0, 255))\n",
    "cv2.imshow(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of tflite_on_python.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
